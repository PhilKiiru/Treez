{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.23.4)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mlxtend) (1.16.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mlxtend) (2.3.2)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mlxtend) (2.3.2)\n",
      "Requirement already satisfied: scikit-learn>=1.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mlxtend) (1.7.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mlxtend) (3.10.6)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mlxtend) (1.5.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib>=3.0.0->mlxtend) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn>=1.3.1->mlxtend) (3.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orders preview:\n",
      "   ORDER_ID  BUYER_ID  TOTAL_PRICE ORDER_STATUS           ORDER_DATE  \\\n",
      "0         6         6       6600.0      PENDING  2025-10-02 05:02:38   \n",
      "1         7         6      10120.0    CANCELLED  2025-10-02 05:10:31   \n",
      "2        23         6       1540.0      PENDING  2025-11-25 06:08:58   \n",
      "3        39         6       3300.0      PENDING  2025-11-25 06:15:47   \n",
      "4        40         6       2850.0      PENDING  2025-11-25 06:16:04   \n",
      "\n",
      "         COMMON_NAME  \n",
      "0   Honeylocust tree  \n",
      "1   Honeylocust tree  \n",
      "2   Honeylocust tree  \n",
      "3   Honeylocust tree  \n",
      "4   Honeylocust tree  \n",
      "\n",
      "Trees preview:\n",
      "  most_recent_observation most_recent_observation_type  common_name  \\\n",
      "0               6/17/2020               inventory_date       Locust   \n",
      "1              06/09/2020               inventory_date          Oak   \n",
      "2              06/03/2020               inventory_date          Ash   \n",
      "3              06/03/2020               inventory_date  Scotch pine   \n",
      "4               5/29/2020               inventory_date  Honeylocust   \n",
      "\n",
      "         scientific_name         city       state  longitude_coordinate  \\\n",
      "0                    NaN  Albuquerque  New Mexico           -106.568366   \n",
      "1                Quercus  Albuquerque  New Mexico           -106.655037   \n",
      "2               Fraxinus  Albuquerque  New Mexico           -106.581127   \n",
      "3       Pinus sylvestris  Albuquerque  New Mexico           -106.575056   \n",
      "4  Gleditsia triacanthos  Albuquerque  New Mexico           -106.716539   \n",
      "\n",
      "   latitude_coordinate                         address   condition  ...  \\\n",
      "0            35.060456                             NaN  dead/dying  ...   \n",
      "1            35.139272   1641 Tierra Del Rio Northwest         NaN  ...   \n",
      "2            35.052176       Us Veterans Hospital Loop  dead/dying  ...   \n",
      "3            35.052450  1606 San Pedro Drive Southeast  dead/dying  ...   \n",
      "4            35.149632    5700 Bogart Street Northwest        good  ...   \n",
      "\n",
      "   retired_date location_type zipcode neighborhood location_name  ward  \\\n",
      "0           NaN           NaN     NaN          NaN           NaN   NaN   \n",
      "1           NaN           NaN     NaN          NaN           NaN   NaN   \n",
      "2           NaN           NaN     NaN          NaN           NaN   NaN   \n",
      "3           NaN           NaN     NaN          NaN           NaN   NaN   \n",
      "4           NaN           NaN     NaN          NaN           NaN   NaN   \n",
      "\n",
      "   district  overhead_utility  diameter_breast_height_CM  percent_population  \n",
      "0       NaN               NaN                        NaN                 NaN  \n",
      "1       NaN               NaN                        NaN                 NaN  \n",
      "2       NaN               NaN                        NaN                 NaN  \n",
      "3       NaN               NaN                        NaN                 NaN  \n",
      "4       NaN               NaN                        NaN                 NaN  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data from local CSV files\n",
    "orders = pd.read_csv('Machine learning/philkiiru_orders.csv')\n",
    "trees = pd.read_csv('Machine learning/treez.csv.csv', low_memory=False)\n",
    "print('Orders preview:')\n",
    "print(orders.head())\n",
    "print('\\nTrees preview:')\n",
    "print(trees.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing trees in trees DataFrame: {'cypress', 'jacaranda', 'pinus', 'acacia', 'eucalyptus', 'honeylocust tree', 'flame tree', 'grevillea'}\n",
      "Added 8 missing trees to trees DataFrame.\n",
      "âœ… Filtered orders: 294\n",
      "   ORDER_ID  BUYER_ID  TOTAL_PRICE ORDER_STATUS           ORDER_DATE  \\\n",
      "0         6         6       6600.0      PENDING  2025-10-02 05:02:38   \n",
      "1         7         6      10120.0    CANCELLED  2025-10-02 05:10:31   \n",
      "2        23         6       1540.0      PENDING  2025-11-25 06:08:58   \n",
      "3        39         6       3300.0      PENDING  2025-11-25 06:15:47   \n",
      "4        40         6       2850.0      PENDING  2025-11-25 06:16:04   \n",
      "\n",
      "         COMMON_NAME       common_norm  \n",
      "0   Honeylocust tree  honeylocust tree  \n",
      "1   Honeylocust tree  honeylocust tree  \n",
      "2   Honeylocust tree  honeylocust tree  \n",
      "3   Honeylocust tree  honeylocust tree  \n",
      "4   Honeylocust tree  honeylocust tree  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def normalize_name(s):\n",
    "\tif pd.isna(s): return \"\"\n",
    "\treturn re.sub(r\"[^\\w\\s]\", \"\", str(s).lower().strip())\n",
    "\n",
    "\n",
    "kaggle_common_col = [c for c in trees.columns if \"common\" in c.lower()][0]\n",
    "\n",
    "\n",
    "trees[\"common_norm\"] = trees[kaggle_common_col].apply(normalize_name)\n",
    "orders[\"common_norm\"] = orders[\"COMMON_NAME\"].apply(normalize_name)\n",
    "\n",
    "\n",
    "# Add any missing trees from orders into trees DataFrame (with placeholder info)\n",
    "missing_trees = set(orders['common_norm']) - set(trees['common_norm'])\n",
    "print(f\"Missing trees in trees DataFrame: {missing_trees}\")\n",
    "if missing_trees:\n",
    "\t# Add a row for each missing tree with placeholder values for other columns\n",
    "\tfor tree in missing_trees:\n",
    "\t\tplaceholder = {col: '' for col in trees.columns}\n",
    "\t\tplaceholder['common_norm'] = tree\n",
    "\t\ttrees = pd.concat([trees, pd.DataFrame([placeholder])], ignore_index=True)\n",
    "\tprint(f\"Added {len(missing_trees)} missing trees to trees DataFrame.\")\n",
    "else:\n",
    "\tprint(\"No missing trees to add.\")\n",
    "\n",
    "\n",
    "valid_names = set(trees[\"common_norm\"])\n",
    "orders = orders[orders[\"common_norm\"].isin(valid_names)]\n",
    "\n",
    "\n",
    "print(\"âœ… Filtered orders:\", len(orders))\n",
    "print(orders.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample transaction baskets:\n",
      "['austrian pine', 'deodar cedar', 'grevillea', 'london plane', 'texas red oak']\n",
      "['crabapple', 'cypress', 'desert willow', 'siberian elm']\n",
      "['crabapple']\n",
      "['honeylocust tree', 'austrian pine', 'bur oak', 'cottonwood', 'crabapple', 'deodar cedar', 'flame tree', 'siberian elm', 'texas red oak']\n",
      "['honeylocust tree', 'austrian pine', 'bur oak', 'crabapple', 'deodar cedar', 'desert willow', 'flame tree', 'grevillea', 'london plane', 'siberian elm', 'texas red oak']\n"
     ]
    }
   ],
   "source": [
    "transactions = orders.groupby(\"ORDER_ID\")[\"common_norm\"].apply(list).tolist()\n",
    "print(\"Sample transaction baskets:\")\n",
    "for t in transactions[:5]:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Strong rules found: 3722\n",
      "                       antecedents      consequents  support  confidence  \\\n",
      "166               (ponderosa pine)    (scotch pine)    0.024        0.75   \n",
      "172       (austrian pine, bur oak)      (crabapple)    0.024        1.00   \n",
      "174           (bur oak, crabapple)  (austrian pine)    0.024        0.75   \n",
      "184    (flame tree, austrian pine)        (bur oak)    0.016        1.00   \n",
      "185          (flame tree, bur oak)  (austrian pine)    0.016        1.00   \n",
      "192    (bur oak, honeylocust tree)  (austrian pine)    0.016        1.00   \n",
      "196  (siberian elm, austrian pine)        (bur oak)    0.016        1.00   \n",
      "197        (siberian elm, bur oak)  (austrian pine)    0.016        1.00   \n",
      "210      (deodar cedar, crabapple)  (austrian pine)    0.016        1.00   \n",
      "214    (flame tree, austrian pine)      (crabapple)    0.016        1.00   \n",
      "\n",
      "          lift  \n",
      "166  10.416667  \n",
      "172  10.416667  \n",
      "174   6.696429  \n",
      "184  10.416667  \n",
      "185   8.928571  \n",
      "192   8.928571  \n",
      "196  10.416667  \n",
      "197   8.928571  \n",
      "210   8.928571  \n",
      "214  10.416667  \n"
     ]
    }
   ],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df_enc = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Use lower thresholds for sparse/small datasets\n",
    "min_support = 0.01  # Lowered for more results\n",
    "min_confidence = 0.1\n",
    "\n",
    "frequent_itemsets = apriori(df_enc, min_support=min_support, use_colnames=True)\n",
    "if frequent_itemsets.empty:\n",
    "    print(f\"âš ï¸ No frequent itemsets found with min_support={min_support}. Try lowering it further or check your data.\")\n",
    "    rules = pd.DataFrame()\n",
    "    strong_rules = pd.DataFrame()\n",
    "else:\n",
    "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
    "    if rules.empty:\n",
    "        print(f\"âš ï¸ No association rules found with min_confidence={min_confidence}. Try lowering it further.\")\n",
    "        strong_rules = pd.DataFrame()\n",
    "    else:\n",
    "        strong_rules = rules[(rules[\"confidence\"] >= 0.7) & (rules[\"lift\"] > 1)]\n",
    "        print(\"âœ… Strong rules found:\", len(strong_rules))\n",
    "        print(strong_rules[[\"antecedents\",\"consequents\",\"support\",\"confidence\",\"lift\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ If buyer gets ['deodar cedar', 'crabapple'] â†’ recommend ['flame tree', 'austrian pine'] (conf=1.00, lift=62.50)\n",
      "ðŸ’¡ If buyer gets ['deodar cedar', 'crabapple'] â†’ recommend ['austrian pine', 'siberian elm'] (conf=1.00, lift=62.50)\n",
      "ðŸ’¡ If buyer gets ['deodar cedar', 'crabapple'] â†’ recommend ['flame tree', 'bur oak'] (conf=1.00, lift=62.50)\n",
      "ðŸ’¡ If buyer gets ['deodar cedar', 'crabapple'] â†’ recommend ['bur oak', 'honeylocust tree'] (conf=1.00, lift=62.50)\n",
      "ðŸ’¡ If buyer gets ['deodar cedar', 'crabapple'] â†’ recommend ['siberian elm', 'bur oak'] (conf=1.00, lift=62.50)\n"
     ]
    }
   ],
   "source": [
    "def recommend(tree, rules_df=strong_rules, top_n=5):\n",
    "    recs = rules_df[rules_df['antecedents'].apply(lambda x: tree in x)]\n",
    "    if recs.empty:\n",
    "        print(f\"No recommendations for {tree}\")\n",
    "        return\n",
    "    recs = recs.sort_values(by=[\"confidence\",\"lift\"], ascending=False)\n",
    "    for _, r in recs.head(top_n).iterrows():\n",
    "        print(f\"ðŸ’¡ If buyer gets {list(r['antecedents'])} â†’ recommend {list(r['consequents'])} \"\n",
    "              f\"(conf={r['confidence']:.2f}, lift={r['lift']:.2f})\")\n",
    "\n",
    "# for instance\n",
    "recommend(\"crabapple\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported recommendations to ml/recommendations.csv\n"
     ]
    }
   ],
   "source": [
    "# Export recommendations to CSV for use in your PHP project\n",
    "export_cols = [\"antecedents\", \"consequents\", \"support\", \"confidence\", \"lift\"]\n",
    "rules_to_export = rules.copy()\n",
    "rules_to_export[\"antecedents\"] = rules_to_export[\"antecedents\"].apply(lambda x: ', '.join(list(x)))\n",
    "rules_to_export[\"consequents\"] = rules_to_export[\"consequents\"].apply(lambda x: ', '.join(list(x)))\n",
    "rules_to_export[export_cols].to_csv(\"ml/recommendations.csv\", index=False)\n",
    "print(\"Exported recommendations to ml/recommendations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported recommendations with images to ml/recommendations.csv\n"
     ]
    }
   ],
   "source": [
    "# Add image path for each recommended tree (consequent) and export to CSV\n",
    "import os\n",
    "\n",
    "# List all files in uploads directory\n",
    "uploads_dir = 'uploads'\n",
    "upload_files = os.listdir(uploads_dir)\n",
    "\n",
    "# Helper to find best image match for a tree name\n",
    "import difflib\n",
    "def find_best_image(tree_name, files):\n",
    "    tree_name = tree_name.lower().replace(' ', '')\n",
    "    candidates = [f for f in files if tree_name in f.lower().replace(' ', '')]\n",
    "    if candidates:\n",
    "        return os.path.join(uploads_dir, candidates[0])\n",
    "    # fallback: closest match\n",
    "    match = difflib.get_close_matches(tree_name, [f.lower().replace(' ', '') for f in files], n=1)\n",
    "    if match:\n",
    "        idx = [f.lower().replace(' ', '') for f in files].index(match[0])\n",
    "        return os.path.join(uploads_dir, files[idx])\n",
    "    return ''\n",
    "\n",
    "rules_to_export = rules.copy()\n",
    "rules_to_export[\"antecedents\"] = rules_to_export[\"antecedents\"].apply(lambda x: ', '.join(list(x)))\n",
    "rules_to_export[\"consequents\"] = rules_to_export[\"consequents\"].apply(lambda x: ', '.join(list(x)))\n",
    "rules_to_export[\"consequent_image\"] = rules_to_export[\"consequents\"].apply(lambda x: find_best_image(x, upload_files))\n",
    "export_cols = [\"antecedents\", \"consequents\", \"consequent_image\", \"support\", \"confidence\", \"lift\"]\n",
    "rules_to_export[export_cols].to_csv(\"ml/recommendations.csv\", index=False)\n",
    "print(\"Exported recommendations with images to ml/recommendations.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPAFTH3flx4Xbs7K6h6dlbP",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
